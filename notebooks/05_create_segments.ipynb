{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc0b0504",
   "metadata": {},
   "source": [
    "# Phrase grouping concatentation into editable segments\n",
    "\n",
    "The last step generated a groupings JSON, e.g.:\n",
    "\n",
    "```json\n",
    "[\n",
    "  [0, 1, 3],\n",
    "  [5],\n",
    "  [6, 7, 8]\n",
    "]\n",
    "```\n",
    "\n",
    "In this step, we're taking that and going back to the source transcript to output a TSV file like this:\n",
    "\n",
    "```tsv\n",
    "0-3\tThank you and good afternoon. It's great to be back in Chicago. Um And thanks for that kind introduction.\n",
    "5-5\tUm, so I'm, I'm looking forward to our conversation, my conversation, uh, with, uh, uh, Professor Rajan Rahu, but first I'll briefly discuss the outlook for the economy and monetary policy.\n",
    "6-8\tSo at the Fed, we are always focused on the dual mandate goals that Congress has given us maximum employment and stable prices. Despite heightened uncertainty and downside risks, the US economy is still in a solid position. The labor market is at or near maximum employment. Inflation has come down a great deal, but it's still running a bit above our 2% objective.\n",
    "```\n",
    "\n",
    "Each of the lines above should be a compmlete thought; it should be something that can be cut and edited as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a073afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to content/gYXAulePuXY-segments.tsv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "VIDEO_ID = 'gYXAulePuXY'\n",
    "\n",
    "transcription_file = f\"content/{VIDEO_ID}-transcript.json\"\n",
    "groupings_file = f\"content/{VIDEO_ID}-groupings.json\"\n",
    "output_file = f\"content/{VIDEO_ID}-segments.tsv\"\n",
    "\n",
    "# Load the transcription from AWS Transcribe\n",
    "with open(transcription_file, 'r') as f:\n",
    "    transcription = json.load(f)\n",
    "\n",
    "# Load the phrase groupings (from an LLM)\n",
    "with open(groupings_file, 'r') as f:\n",
    "    groupings = json.load(f)\n",
    "\n",
    "# Get the phrases portion of the transcription_file\n",
    "audio_segments = transcription.get('results', {}).get('audio_segments', [])\n",
    "\n",
    "# Create a lookup dictionary from source\n",
    "id_to_transcript = {item[\"id\"]: item[\"transcript\"] for item in audio_segments}\n",
    "\n",
    "# Expand each selection to a full range from first to last ID\n",
    "expanded_selections = [\n",
    "    list(range(group[0], group[-1] + 1)) if group else []\n",
    "    for group in groupings\n",
    "]\n",
    "\n",
    "# Replace IDs in selections with transcripts if available\n",
    "editable_segments = [\n",
    "    [f\"{group[0]}-{group[-1]}\", ' '.join([id_to_transcript.get(id_, id_) for id_ in group])]\n",
    "    for group in expanded_selections\n",
    "]\n",
    "\n",
    "# Write the segments to a new file\n",
    "with open(output_file, 'w', newline='') as tsvfile:\n",
    "   tsv_writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "   tsv_writer.writerows(editable_segments)\n",
    "\n",
    "print(f\"Data written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
